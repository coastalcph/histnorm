
model-ensemble3: !Experiment
  exp_global: &exp_global !ExpGlobal
    model_file: '<<TMPDIR>>/{EXP}.mod'
    log_file: '<<TMPDIR>>/{EXP}.log'
    default_layer_dim: 300
    dropout: 0.2

  model: !DefaultTranslator
    src_reader: !PlainTextReader
      _xnmt_id: the_src_reader
      vocab: !Vocab {vocab_file: "<<TMPDIR>>/train.src.vocab"}
    trg_reader: !PlainTextReader
      _xnmt_id: the_trg_reader
      vocab: !Vocab {vocab_file: "<<TMPDIR>>/train.trg.vocab"}
    src_embedder: !SimpleWordEmbedder
      emb_dim: 60
    encoder: !BiLSTMSeqTransducer
      layers: 1
      input_dim: 60
      hidden_dim: 300
    attender: !MlpAttender
      hidden_dim: 300
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 60
    decoder: !MlpSoftmaxDecoder
      rnn_layer: !UniLSTMSeqTransducer
        layers: 1
      trg_embed_dim: 60
      mlp_layer: !MLP
        hidden_dim: 300
      bridge: !CopyBridge {}

  train: !SimpleTrainingRegimen
    batcher: !SentShuffleBatcher
      batch_size: 25
    trainer: !AdamTrainer
      alpha: 0.001
    run_for_epochs: 1000
    lr_decay: 0.01
    lr_decay_times: 0
    patience: <<PATIENCE>>

    src_file: "<<TMPDIR>>/train.src"
    trg_file: "<<TMPDIR>>/train.trg"
    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: accuracy
        src_file: "<<TMPDIR>>/dev.src"
        ref_file: "<<TMPDIR>>/dev.trg"
        hyp_file: "<<TMPDIR>>/dev.hyp"

  evaluate: &evaluate
    - !AccuracyEvalTask
      eval_metrics: accuracy
      src_file: "/home/ubuntu/data/xnmt/hist/<<DATASET>>/dev.orig"
      ref_file: "/home/ubuntu/data/xnmt/hist/<<DATASET>>/dev.norm"
      hyp_file: "<<TMPDIR>>/full_dev.norm"
      inference: !SimpleInference
        search_strategy: !BeamSearch
          beam_size: 5
#    - !AccuracyEvalTask
#      eval_metrics: bleu
#      src_file: "/home/ubuntu/data/xnmt/hist/<<DATASET>>/test.orig"
#      ref_file: "/home/ubuntu/data/xnmt/hist/<<DATASET>>/test.norm"
#      hyp_file: "<<TMPDIR>>/full_test.norm"
#      inference: !SimpleInference
#        beam: 5
